{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similar_keyphrases(input, m_kav_mean):    \n",
    "    cs = cosine_similarity(m_kav_mean[input].reshape(1, -1),m_kav_mean)[0]\n",
    "    cands = cs.argsort()[::-1][1:6]\n",
    "    return cands\n",
    "\n",
    "def get_similar_keyphrases_movies(input, m_kav_mean, m_items):\n",
    "    cs = cosine_similarity(m_kav_mean[input].reshape(1, -1),m_items)[0]\n",
    "    cands = cs.argsort()[::-1][:5]\n",
    "    return cands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = pd.read_csv('./data/ml10/fold0_valid/fold0/tr_tags.csv')\n",
    "\n",
    "rows, cols = df_tags.item, df_tags.tag\n",
    "values = np.ones(len(df_tags))\n",
    "\n",
    "m_item_keyphrase= sp.csr_matrix((values, (rows, cols)), dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ml10/tag_id_dict.json') as f:\n",
    "    tag_id_dict = json.load(f)\n",
    "with open('./data/ml10/title_id_dict.json') as f:\n",
    "    title_id_dict = json.load(f)\n",
    "\n",
    "id_tag_dict = {id: tag for tag, id in tag_id_dict.items()}\n",
    "id_title_dict = {id: title for title, id in title_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saves/ml10/VAE_beta_multilayer.pt'\n",
    "model = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "item_embeddings = model.decoder.weight.detach().numpy()\n",
    "item_bias = model.decoder.bias.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7199750208854672"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(item_bias,0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "1%|          | 1/164 [00:00<00:21,  7.50it/s]Generate Keyphrase Activation Vector\n100%|██████████| 164/164 [00:20<00:00,  8.07it/s](164, 100, 150)\n\n"
    }
   ],
   "source": [
    "from utils.KAVgenerator import KAVgenerator\n",
    "k = KAVgenerator(m_item_keyphrase,item_embeddings, 1)\n",
    "keyphrase_embeddings = k.get_all_mean_kav(20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.8881551"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.linalg.norm(item_embeddings, ord=2, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7861438428950553"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.linalg.norm(keyphrase_embeddings, ord=2, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['space', 'future', 'action', 'robots', 'dystopia']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['sci-fi']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['sci-fi'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['history', 'historical', 'true story', 'oscar (best actor)', 'war']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['world war ii']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['world war ii'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['adventure', 'magic', 'super-hero', 'superhero', 'epic']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['fantasy']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['fantasy'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['oscar (best picture)', 'war', 'oscar (best actor)', 'interesting', 'true story']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['drama']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['hitchcock', 'classic', 'film noir', 'oscar (best picture)', 'black and white']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['alfred hitchcock']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['alfred hitchcock'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['quirky', 'black comedy', 'surreal', 'satire', 'nonlinear']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['dark comedy']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['dark comedy'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['parody', 'satire', 'comedy', 'spoof', 'funny']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['hilarious']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['hilarious'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['funny', 'parody', 'hilarious', 'jim carrey', 'stupid']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['comedy']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['comedy'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['girlie movie', 'chick flick', 'cute', 'family', 'new york city']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['romance']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['romance'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['post apocalyptic', 'zombies', 'horror', 'aliens', 'vampire']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['post-apocalyptic']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['post-apocalyptic'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['violent', 'quirky', 'overrated', 'mafia', 'martin scorsese']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['film noir']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['film noir'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['documentary', 'based on a true story', 'africa', 'sad', 'racism']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['politics']\n",
    "cands = get_similar_keyphrases(id, keyphrase_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_tag_dict[kp])\n",
    "print(output)\n",
    "outputs.append(['politics'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sci-fi</th>\n      <td>space</td>\n      <td>future</td>\n      <td>action</td>\n      <td>robots</td>\n      <td>dystopia</td>\n    </tr>\n    <tr>\n      <th>world war ii</th>\n      <td>history</td>\n      <td>historical</td>\n      <td>true story</td>\n      <td>oscar (best actor)</td>\n      <td>war</td>\n    </tr>\n    <tr>\n      <th>fantasy</th>\n      <td>adventure</td>\n      <td>magic</td>\n      <td>super-hero</td>\n      <td>superhero</td>\n      <td>epic</td>\n    </tr>\n    <tr>\n      <th>alfred hitchcock</th>\n      <td>hitchcock</td>\n      <td>classic</td>\n      <td>film noir</td>\n      <td>oscar (best picture)</td>\n      <td>black and white</td>\n    </tr>\n    <tr>\n      <th>dark comedy</th>\n      <td>quirky</td>\n      <td>black comedy</td>\n      <td>surreal</td>\n      <td>satire</td>\n      <td>nonlinear</td>\n    </tr>\n    <tr>\n      <th>hilarious</th>\n      <td>parody</td>\n      <td>satire</td>\n      <td>comedy</td>\n      <td>spoof</td>\n      <td>funny</td>\n    </tr>\n    <tr>\n      <th>comedy</th>\n      <td>funny</td>\n      <td>parody</td>\n      <td>hilarious</td>\n      <td>jim carrey</td>\n      <td>stupid</td>\n    </tr>\n    <tr>\n      <th>romance</th>\n      <td>girlie movie</td>\n      <td>chick flick</td>\n      <td>cute</td>\n      <td>family</td>\n      <td>new york city</td>\n    </tr>\n    <tr>\n      <th>post-apocalyptic</th>\n      <td>post apocalyptic</td>\n      <td>zombies</td>\n      <td>horror</td>\n      <td>aliens</td>\n      <td>vampire</td>\n    </tr>\n    <tr>\n      <th>film noir</th>\n      <td>violent</td>\n      <td>quirky</td>\n      <td>overrated</td>\n      <td>mafia</td>\n      <td>martin scorsese</td>\n    </tr>\n    <tr>\n      <th>politics</th>\n      <td>documentary</td>\n      <td>based on a true story</td>\n      <td>africa</td>\n      <td>sad</td>\n      <td>racism</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                 1                      2           3  \\\nsci-fi                       space                 future      action   \nworld war ii               history             historical  true story   \nfantasy                  adventure                  magic  super-hero   \nalfred hitchcock         hitchcock                classic   film noir   \ndark comedy                 quirky           black comedy     surreal   \nhilarious                   parody                 satire      comedy   \ncomedy                       funny                 parody   hilarious   \nromance               girlie movie            chick flick        cute   \npost-apocalyptic  post apocalyptic                zombies      horror   \nfilm noir                  violent                 quirky   overrated   \npolitics               documentary  based on a true story      africa   \n\n                                     4                5  \nsci-fi                          robots         dystopia  \nworld war ii        oscar (best actor)              war  \nfantasy                      superhero             epic  \nalfred hitchcock  oscar (best picture)  black and white  \ndark comedy                     satire        nonlinear  \nhilarious                        spoof            funny  \ncomedy                      jim carrey           stupid  \nromance                         family    new york city  \npost-apocalyptic                aliens          vampire  \nfilm noir                        mafia  martin scorsese  \npolitics                           sad           racism  "
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(outputs).set_index(0)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Spider-Man 2', 'X-Men', 'X2: X-Men United', 'Spider-Man', 'Left Behind: World at War']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['superhero']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['superhero'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Home Page', 'Year of the Dog', 'Distant (Uzak)', 'Children Underground', 'Julien Donkey-Boy']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['documentary']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['documentary'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Star Wars: Episode VI - Return of the Jedi', 'Star Wars: Episode IV - A New Hope (a.k.a. Star Wars)', 'Star Wars: Episode V - The Empire Strikes Back', 'Terminator 2: Judgment Day', 'Star Wars: Episode I - The Phantom Menace']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['sci-fi']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['sci-fi'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Freddy Vs. Jason', 'Mummy Returns, The', 'Blade II', 'Mummy, The', 'Scream 3']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['marvel']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Beauty and the Beast', 'Babe', 'Sound of Music, The', 'Sense and Sensibility', 'Little Mermaid, The']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['family']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['family'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Fahrenheit 9/11', 'Inconvenient Truth, An', 'Unprecedented: The 2000 Presidential Election', 'Brokeback Mountain', 'Story of the Weeping Camel, The (Die Geschichte vom weinenden Kamel)']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['politics']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['politics'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Beauty and the Beast', 'Toy Story 2', 'Little Mermaid, The', 'Toy Story', 'Aladdin']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['fairy tale']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['fairy tale'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Lord of the Rings: The Return of the King, The', 'Lord of the Rings: The Fellowship of the Ring, The', 'Lord of the Rings: The Two Towers, The', 'Star Wars: Episode VI - Return of the Jedi', 'Star Wars: Episode IV - A New Hope (a.k.a. Star Wars)']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['fantasy']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['fantasy'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>superhero</th>\n      <td>Spider-Man 2</td>\n      <td>X-Men</td>\n      <td>X2: X-Men United</td>\n      <td>Spider-Man</td>\n      <td>Left Behind: World at War</td>\n    </tr>\n    <tr>\n      <th>documentary</th>\n      <td>Home Page</td>\n      <td>Year of the Dog</td>\n      <td>Distant (Uzak)</td>\n      <td>Children Underground</td>\n      <td>Julien Donkey-Boy</td>\n    </tr>\n    <tr>\n      <th>sci-fi</th>\n      <td>Star Wars: Episode VI - Return of the Jedi</td>\n      <td>Star Wars: Episode IV - A New Hope (a.k.a. Sta...</td>\n      <td>Star Wars: Episode V - The Empire Strikes Back</td>\n      <td>Terminator 2: Judgment Day</td>\n      <td>Star Wars: Episode I - The Phantom Menace</td>\n    </tr>\n    <tr>\n      <th>family</th>\n      <td>Beauty and the Beast</td>\n      <td>Babe</td>\n      <td>Sound of Music, The</td>\n      <td>Sense and Sensibility</td>\n      <td>Little Mermaid, The</td>\n    </tr>\n    <tr>\n      <th>politics</th>\n      <td>Fahrenheit 9/11</td>\n      <td>Inconvenient Truth, An</td>\n      <td>Unprecedented: The 2000 Presidential Election</td>\n      <td>Brokeback Mountain</td>\n      <td>Story of the Weeping Camel, The (Die Geschicht...</td>\n    </tr>\n    <tr>\n      <th>fairy tale</th>\n      <td>Beauty and the Beast</td>\n      <td>Toy Story 2</td>\n      <td>Little Mermaid, The</td>\n      <td>Toy Story</td>\n      <td>Aladdin</td>\n    </tr>\n    <tr>\n      <th>fantasy</th>\n      <td>Lord of the Rings: The Return of the King, The</td>\n      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n      <td>Lord of the Rings: The Two Towers, The</td>\n      <td>Star Wars: Episode VI - Return of the Jedi</td>\n      <td>Star Wars: Episode IV - A New Hope (a.k.a. Sta...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                          1  \\\nsuperhero                                      Spider-Man 2   \ndocumentary                                       Home Page   \nsci-fi           Star Wars: Episode VI - Return of the Jedi   \nfamily                                 Beauty and the Beast   \npolitics                                    Fahrenheit 9/11   \nfairy tale                             Beauty and the Beast   \nfantasy      Lord of the Rings: The Return of the King, The   \n\n                                                             2  \\\nsuperhero                                                X-Men   \ndocumentary                                    Year of the Dog   \nsci-fi       Star Wars: Episode IV - A New Hope (a.k.a. Sta...   \nfamily                                                    Babe   \npolitics                                Inconvenient Truth, An   \nfairy tale                                         Toy Story 2   \nfantasy      Lord of the Rings: The Fellowship of the Ring,...   \n\n                                                          3  \\\nsuperhero                                  X2: X-Men United   \ndocumentary                                  Distant (Uzak)   \nsci-fi       Star Wars: Episode V - The Empire Strikes Back   \nfamily                                  Sound of Music, The   \npolitics      Unprecedented: The 2000 Presidential Election   \nfairy tale                              Little Mermaid, The   \nfantasy              Lord of the Rings: The Two Towers, The   \n\n                                                      4  \\\nsuperhero                                    Spider-Man   \ndocumentary                        Children Underground   \nsci-fi                       Terminator 2: Judgment Day   \nfamily                            Sense and Sensibility   \npolitics                             Brokeback Mountain   \nfairy tale                                    Toy Story   \nfantasy      Star Wars: Episode VI - Return of the Jedi   \n\n                                                             5  \nsuperhero                            Left Behind: World at War  \ndocumentary                                  Julien Donkey-Boy  \nsci-fi               Star Wars: Episode I - The Phantom Menace  \nfamily                                     Little Mermaid, The  \npolitics     Story of the Weeping Camel, The (Die Geschicht...  \nfairy tale                                             Aladdin  \nfantasy      Star Wars: Episode IV - A New Hope (a.k.a. Sta...  "
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(outputs).set_index(0)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['North by Northwest', 'M', 'Notorious', 'Shadow of a Doubt', 'Strangers on a Train']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['hitchcock']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['hitchcock'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[\"Mr. Holland's Opus\", 'Sleepless in Seattle', 'Apollo 13', 'Forrest Gump', 'Mrs. Doubtfire']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['tom hanks']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['tom hanks'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Forrest Gump', 'Mission: Impossible', 'Braveheart', 'Legends of the Fall', 'Shawshank Redemption, The']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['tom cruise']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['tom cruise'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Seven (a.k.a. Se7en)', 'Fight Club', 'Gladiator', 'Forrest Gump', 'American History X']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['brad pitt']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['brad pitt'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Ace Ventura: When Nature Calls', 'Dumb & Dumber', 'Ace Ventura: Pet Detective', 'Cable Guy, The', 'Happy Gilmore']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['jim carrey']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['jim carrey'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Armageddon', 'Gone in 60 Seconds', 'Matrix, The', 'End of Days', 'Swordfish']\n"
    }
   ],
   "source": [
    "id = tag_id_dict['bruce willis']\n",
    "cands = get_similar_keyphrases_movies(id, keyphrase_embeddings,item_embeddings)\n",
    "output = []\n",
    "for kp in cands:\n",
    "    output.append(id_title_dict[kp][:-7])\n",
    "print(output)\n",
    "outputs.append(['bruce willis'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>hitchcock</th>\n      <td>North by Northwest</td>\n      <td>M</td>\n      <td>Notorious</td>\n      <td>Shadow of a Doubt</td>\n      <td>Strangers on a Train</td>\n    </tr>\n    <tr>\n      <th>tom hanks</th>\n      <td>Mr. Holland's Opus</td>\n      <td>Sleepless in Seattle</td>\n      <td>Apollo 13</td>\n      <td>Forrest Gump</td>\n      <td>Mrs. Doubtfire</td>\n    </tr>\n    <tr>\n      <th>tom cruise</th>\n      <td>Forrest Gump</td>\n      <td>Mission: Impossible</td>\n      <td>Braveheart</td>\n      <td>Legends of the Fall</td>\n      <td>Shawshank Redemption, The</td>\n    </tr>\n    <tr>\n      <th>brad pitt</th>\n      <td>Seven (a.k.a. Se7en)</td>\n      <td>Fight Club</td>\n      <td>Gladiator</td>\n      <td>Forrest Gump</td>\n      <td>American History X</td>\n    </tr>\n    <tr>\n      <th>jim carrey</th>\n      <td>Ace Ventura: When Nature Calls</td>\n      <td>Dumb &amp; Dumber</td>\n      <td>Ace Ventura: Pet Detective</td>\n      <td>Cable Guy, The</td>\n      <td>Happy Gilmore</td>\n    </tr>\n    <tr>\n      <th>bruce willis</th>\n      <td>Armageddon</td>\n      <td>Gone in 60 Seconds</td>\n      <td>Matrix, The</td>\n      <td>End of Days</td>\n      <td>Swordfish</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                           1                     2  \\\nhitchcock                 North by Northwest                     M   \ntom hanks                 Mr. Holland's Opus  Sleepless in Seattle   \ntom cruise                      Forrest Gump   Mission: Impossible   \nbrad pitt               Seven (a.k.a. Se7en)            Fight Club   \njim carrey    Ace Ventura: When Nature Calls         Dumb & Dumber   \nbruce willis                      Armageddon    Gone in 60 Seconds   \n\n                                       3                    4  \\\nhitchcock                      Notorious    Shadow of a Doubt   \ntom hanks                      Apollo 13         Forrest Gump   \ntom cruise                    Braveheart  Legends of the Fall   \nbrad pitt                      Gladiator         Forrest Gump   \njim carrey    Ace Ventura: Pet Detective       Cable Guy, The   \nbruce willis                 Matrix, The          End of Days   \n\n                                      5  \nhitchcock          Strangers on a Train  \ntom hanks                Mrs. Doubtfire  \ntom cruise    Shawshank Redemption, The  \nbrad pitt            American History X  \njim carrey                Happy Gilmore  \nbruce willis                  Swordfish  "
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(outputs).set_index(0)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'anime': 0,\n 'super-hero': 1,\n 'woody allen': 2,\n 'comic book': 3,\n 'samuel l jackson': 4,\n 'brad pitt': 5,\n 'bruce willis': 6,\n 'time travel': 7,\n 'crime': 8,\n 'serial killer': 9,\n 'action': 10,\n 'jim carrey': 11,\n 'stupid': 12,\n 'dystopia': 13,\n 'drama': 14,\n 'aliens': 15,\n 'based on a book': 16,\n 'classic': 17,\n 'fantasy': 18,\n 'sci-fi': 19,\n 'space': 20,\n 'arnold schwarzenegger': 21,\n 'matt damon': 22,\n 'oscar (best actor)': 23,\n 'oscar (best picture)': 24,\n 'ghosts': 25,\n 'twist ending': 26,\n 'stephen king': 27,\n 'tom hanks': 28,\n 'interesting': 29,\n 'dvd': 30,\n 'nicolas cage': 31,\n 'magic': 32,\n 'morgan freeman': 33,\n 'bond': 34,\n 'music': 35,\n 'gay': 36,\n 'comedy': 37,\n 'funny': 38,\n 'alfred hitchcock': 39,\n 'true story': 40,\n 'family': 41,\n 'film noir': 42,\n 'heist': 43,\n 'quirky': 44,\n 'sequel': 45,\n 'memory': 46,\n 'psychology': 47,\n 'espionage': 48,\n 'satire': 49,\n 'shakespeare': 50,\n 'black comedy': 51,\n 'adventure': 52,\n 'girlie movie': 53,\n 'teen': 54,\n 'disney': 55,\n 'british': 56,\n 'sports': 57,\n 'hitchcock': 58,\n 'japan': 59,\n 'depressing': 60,\n 'great movie': 61,\n 'overrated': 62,\n 'robin williams': 63,\n 'racism': 64,\n 'boring': 65,\n 'dark comedy': 66,\n 'chick flick': 67,\n 'religion': 68,\n 'holocaust': 69,\n 'world war ii': 70,\n 'mental illness': 71,\n 'martin scorsese': 72,\n 'tom cruise': 73,\n 'steven spielberg': 74,\n 'superhero': 75,\n 'nudity (topless)': 76,\n 'drugs': 77,\n 'mystery': 78,\n 'nonlinear': 79,\n 'revenge': 80,\n 'documentary': 81,\n 'nudity (topless - brief)': 82,\n 'clint eastwood': 83,\n 'england': 84,\n 'zombies': 85,\n 'jude law': 86,\n 'hilarious': 87,\n '007': 88,\n 'james bond': 89,\n 'post-apocalyptic': 90,\n 'based on a true story': 91,\n 'vampire': 92,\n 'politics': 93,\n 'marvel': 94,\n 'animation': 95,\n 'parody': 96,\n 'police': 97,\n 'suicide': 98,\n 'historical': 99,\n 'scary': 100,\n 'fun': 101,\n 'love': 102,\n 'vampires': 103,\n 'murder': 104,\n 'thriller': 105,\n 'horror': 106,\n 'johnny depp': 107,\n 'surreal': 108,\n 'musical': 109,\n 'mel gibson': 110,\n 'remake': 111,\n 'sean connery': 112,\n 'romance': 113,\n 'violence': 114,\n 'london': 115,\n 'war': 116,\n 'martial arts': 117,\n 'lesbian': 118,\n 'death': 119,\n 'black and white': 120,\n 'cute': 121,\n 'seen more than once': 122,\n 'dark': 123,\n 'beautiful': 124,\n 'sad': 125,\n 'history': 126,\n 'disturbing': 127,\n 'children': 128,\n 'france': 129,\n 'terrorism': 130,\n 'fairy tale': 131,\n 'spoof': 132,\n 'paris': 133,\n 'cult film': 134,\n 'prison': 135,\n 'mafia': 136,\n 'organized crime': 137,\n 'predictable': 138,\n 'new york city': 139,\n 'great soundtrack': 140,\n 'underrated': 141,\n 'suspense': 142,\n 'baseball': 143,\n 'conspiracy': 144,\n 'cannibalism': 145,\n 'robots': 146,\n 'high school': 147,\n 'christmas': 148,\n 'nazis': 149,\n 'harrison ford': 150,\n 'coming of age': 151,\n 'epic': 152,\n 'new york': 153,\n 'post apocalyptic': 154,\n 'intense': 155,\n 'violent': 156,\n 'slow': 157,\n 'africa': 158,\n 'future': 159,\n 'biography': 160,\n 'boxing': 161,\n 'los angeles': 162,\n 'cars': 163}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_tag_dict\n",
    "tag_id_dict = {v:k for k, v in id_tag_dict.items()}\n",
    "tag_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Read data from ./data/ml10/fold0_valid/fold0/\n"
    }
   ],
   "source": [
    "from utils.Dataset import Dataset\n",
    "dataset = Dataset(data_dir='./data/ml10/fold0_valid/fold0/',load_keyphrases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info(user_id, input_matrix):\n",
    "    user_input = input_matrix[user_id]\n",
    "    nonzeros = user_input.nonzero()\n",
    "    items = nonzeros[1]\n",
    "    ratings = user_input[nonzeros]\n",
    "    ratings = np.asarray(ratings).reshape(-1)\n",
    "    sorted_ratings_idx = ratings.argsort()[::-1]\n",
    "    sorted_items = items[sorted_ratings_idx]\n",
    "    sorted_ratings = ratings[sorted_ratings_idx]\n",
    "    return sorted_items, sorted_ratings\n",
    "\n",
    "def get_user_preds(user_id, input_matrix):\n",
    "    user_input = input_matrix[user_id]\n",
    "    mask_index = user_input.nonzero()[1]\n",
    "    i = torch.FloatTensor(user_input.toarray()).to(torch.device('cpu'))\n",
    "    with torch.no_grad():\n",
    "        preds = model.forward(i).cpu().numpy()\n",
    "    preds = np.asarray(preds).reshape(-1)\n",
    "    preds[mask_index] = -np.inf\n",
    "    sorted_pred_items = preds.argsort()[::-1]\n",
    "    sorted_pred_ratings = preds[sorted_pred_items] \n",
    "    return sorted_pred_items, sorted_pred_ratings\n",
    "\n",
    "def get_mu_cov(user_id, input_matrix, moddel):\n",
    "    user_input = input_matrix[user_id]\n",
    "    i = torch.FloatTensor(user_input.toarray()).to(torch.device('cpu'))\n",
    "    with torch.no_grad():\n",
    "        mu, logvar = model.get_mu_logvar(i)\n",
    "    std = model.logvar2std(logvar)\n",
    "    mu, std = mu.numpy().T, std.numpy()\n",
    "\n",
    "    return mu, np.diagflat(std*std)\n",
    "\n",
    "def get_user_preds_using_mu(user_mu, input_matrix, model):\n",
    "    user_input = input_matrix[user_id]\n",
    "    mask_index = user_input.nonzero()[1]\n",
    "    _mu = torch.FloatTensor(user_mu.T)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model.decoder(_mu)\n",
    "    preds = np.asarray(preds).reshape(-1)\n",
    "    preds[mask_index] = -np.inf\n",
    "    sorted_pred_items = preds.argsort()[::-1]\n",
    "    sorted_pred_ratings = preds[sorted_pred_items] \n",
    "    return sorted_pred_items, sorted_pred_ratings\n",
    "\n",
    "def update_posterior(x, y, S_0, m_0, prec_y):\n",
    "    S_0_inv = np.linalg.inv(S_0)\n",
    "    #S_1 = np.linalg.inv(S_0_inv +prec_y * x @ x.T)    \n",
    "    #print(np.swapaxes(x,-2,-1).shape)\n",
    "    S_1 = np.linalg.inv(S_0_inv +prec_y * np.matmul(x,np.swapaxes(x,-2,-1)))\n",
    "    m_1 = S_1 @ (S_0_inv @ m_0 + prec_y * y * x)\n",
    "    #print(m_1.shape)\n",
    "    return S_1, m_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(69878, 10677)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = []\n",
    "dataset.train_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array((m_item_keyphrase[:,37]>0).todense()).squeeze()\n",
    "mask = np.append(mask, [0]*(dataset.train_matrix.shape[1] - len(mask))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([2])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "a[~np.array([1,1,0]).nonzero()[0]]\n",
    "(1-np.array([1,1,0])).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1.6310777839869757\n[[0.22457496]] [[0.8815902]]\n[  79  120  126  174  186  221  231  233  305  400  492  618  638  889\n  917 1015 1351 1853 2132 2305 2808 2940 3117 3748 5704 6610 7588]\n0.22947407\n0.08240308 -0.14707099\n1.5602946\n"
    }
   ],
   "source": [
    "# for all users:\n",
    "    # compute rates\n",
    "    # update\n",
    "    # compute updated_rates\n",
    "    # updated_rates - rates\n",
    "    # separate and add\n",
    "# take average\n",
    "\n",
    "def eval_routine(keyphrase_id, keyphrase_embeddings, train_matrix, model, prec_y):\n",
    "    x = keyphrase_embeddings[keyphrase_id][:,np.newaxis]\n",
    "    mask = np.array((m_item_keyphrase[:,keyphrase_id]>0).todense()).squeeze()\n",
    "    pos_item_ids = mask.nonzero()[0]\n",
    "    neg_item_ids = (1-mask).nonzero()[0]\n",
    "    user_id = 243\n",
    "    mu, cov = get_mu_cov(user_id, train_matrix, model)\n",
    "    diffs = eval_subroutine(mu, cov, model, x, prec_y)\n",
    "    a = np.mean(diffs[pos_item_ids])\n",
    "    b = np.mean(diffs[neg_item_ids])\n",
    "    print(pos_item_ids)\n",
    "    print(a - b)\n",
    "    print(a,b)\n",
    "    print(np.abs(a-b)/np.abs(b))\n",
    "\n",
    "def eval_subroutine(mu, cov, model, x, prec_y):\n",
    "    _mu = torch.FloatTensor(mu.T)\n",
    "    with torch.no_grad():\n",
    "        preds = model.decoder(_mu)\n",
    "    initial_preds = np.asarray(preds).reshape(-1)\n",
    "    y = np.max(mu.T @ keyphrase_embeddings.T)\n",
    "    print(y)\n",
    "    \n",
    "    cov1, mu1 = update_posterior(x, y, cov, mu, prec_y)\n",
    "    _mu = torch.FloatTensor(mu1.T)\n",
    "    with torch.no_grad():\n",
    "        preds = model.decoder(_mu)\n",
    "    updated_preds = np.asarray(preds).reshape(-1)\n",
    "    diffs = updated_preds - initial_preds\n",
    "    print(mu.T@x, mu1.T@x)\n",
    "    return diffs\n",
    "    m_item_keyphrase\n",
    "\n",
    "eval_routine(49, keyphrase_embeddings, dataset.test_matrix, model, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.258443644457296\nhistorical\nworld war ii\nhitchcock\nanime\njapan\n\nteen\nhigh school\nhilarious\nparody\nsatire\n"
    }
   ],
   "source": [
    "def eval_routine(keyphrase_id, keyphrase_embeddings, train_matrix, model, prec_y):\n",
    "    x = keyphrase_embeddings[keyphrase_id][:,np.newaxis]\n",
    "    user_id = 34\n",
    "    mu, cov = get_mu_cov(user_id, train_matrix, model)\n",
    "    diffs = eval_subroutine(mu, cov, model, x, prec_y)\n",
    "    ranks = diffs.argsort()\n",
    "    top5 = ranks[-5:][::-1]\n",
    "    bot5 = ranks[:5]\n",
    "    return top5, bot5\n",
    "\n",
    "\n",
    "def eval_subroutine(mu, cov, model, x, prec_y):\n",
    "    _mu = torch.FloatTensor(mu.T)\n",
    "    with torch.no_grad():\n",
    "        preds = model.decoder(_mu)\n",
    "    initial_preds = np.asarray(preds).reshape(-1)\n",
    "    y = np.max(mu.T @ keyphrase_embeddings.T)\n",
    "    initial_preds = mu.T @ keyphrase_embeddings.T\n",
    "\n",
    "    print(y)\n",
    "    \n",
    "    cov1, mu1 = update_posterior(x, y, cov, mu, prec_y)\n",
    "    updated_preds = np.array(mu1.T @ keyphrase_embeddings.T).squeeze()\n",
    "    #diffs = np.array((updated_preds - initial_preds)/np.abs(initial_preds)).squeeze()\n",
    "    #print(diffs)\n",
    "    return updated_preds\n",
    "\n",
    "\n",
    "top5, bot5 = eval_routine(0, keyphrase_embeddings, dataset.test_matrix, model, 100)\n",
    "\n",
    "for i in top5:\n",
    "    print(id_tag_dict[i])\n",
    "print(\"\")\n",
    "for i in bot5:\n",
    "    print(id_tag_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ea98350bbef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msorted_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtop10_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop10_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "user_id = 100\n",
    "sorted_items, sorted_ratings = get_user_info(user_id, dataset.train_matrix)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "print(output)\n",
    "outputs.append(['user history'] + output)\n",
    "\n",
    "sorted_items, sorted_ratings = get_user_preds(user_id, dataset.train_matrix)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "print(output)\n",
    "outputs.append(['initial recs'] + output)\n",
    "mu, cov = get_mu_cov(user_id, dataset.train_matrix, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5.3573"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ratings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.22689884]])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.T@keyphrase_embeddings[18][:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1.4240211514953711"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(mu.T@(keyphrase_embeddings.T),q=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.5969892978668212"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(mu.T@(item_embeddings.T),q=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(10677, 150)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1.887459740716844 -1.6873800293518968\n"
    }
   ],
   "source": [
    "prec = np.linalg.norm(1/(cov+1e-6))\n",
    "neg = np.min(mu.T @ keyphrase_embeddings.T)\n",
    "pos = np.max(mu.T @ keyphrase_embeddings.T)\n",
    "print(pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "149499200.0"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keyphrase_embeddings[18][:,np.newaxis]\n",
    "y = [[pos]]\n",
    "\n",
    "cov1, mu1 = update_posterior(x, y, cov, mu, np.array(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.41716433]])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu1.T@keyphrase_embeddings[18][:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Lord of the Rings: The Return of the King, The', 'Lord of the Rings: The Two Towers, The', 'Crouching Tiger, Hidden Dragon (Wu hu zang long)', 'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark)', 'Freaks', 'All About Eve', 'Harry Potter and the Goblet of Fire', 'Heathers', 'Sunset Blvd. (a.k.a. Sunset Boulevard)', 'Eternal Sunshine of the Spotless Mind']\n"
    }
   ],
   "source": [
    "sorted_items, sorted_ratings = get_user_preds_using_mu(mu1, dataset.train_matrix, model)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "print(output)\n",
    "outputs.append(['+ fantasy'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keyphrase_embeddings[18][:,np.newaxis]\n",
    "y = [[neg]]\n",
    "\n",
    "cov1, mu1 = update_posterior(x, y, cov, mu, np.array(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Swimmer, The', 'Sunrise: A Song of Two Humans', 'Freaks', 'Brokeback Mountain', 'Shoot the Moon', 'Lord of the Rings: The Return of the King, The', 'Night of the Hunter, The', 'Lord of the Rings: The Two Towers, The', 'Ball of Fire', 'Chaos']\n"
    }
   ],
   "source": [
    "sorted_items, sorted_ratings = get_user_preds_using_mu(mu1, dataset.train_matrix, model)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "print(output)\n",
    "outputs.append(['- fantasy'] + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>user history</th>\n      <td>Talk to Her (Hable con Ella)</td>\n      <td>Amores Perros (Love's a Bitch)</td>\n      <td>Rosencrantz and Guildenstern Are Dead</td>\n      <td>Identity</td>\n      <td>Mariachi, El</td>\n      <td>It Happened One Night</td>\n      <td>Flirting With Disaster</td>\n      <td>Once Upon a Time in America</td>\n      <td>Drugstore Cowboy</td>\n      <td>Father of the Bride</td>\n    </tr>\n    <tr>\n      <th>initial recs</th>\n      <td>Swimmer, The</td>\n      <td>Freaks</td>\n      <td>Sunrise: A Song of Two Humans</td>\n      <td>Brokeback Mountain</td>\n      <td>Lord of the Rings: The Return of the King, The</td>\n      <td>Shoot the Moon</td>\n      <td>Night of the Hunter, The</td>\n      <td>Lord of the Rings: The Two Towers, The</td>\n      <td>Ball of Fire</td>\n      <td>Sunset Blvd. (a.k.a. Sunset Boulevard)</td>\n    </tr>\n    <tr>\n      <th>+ fantasy</th>\n      <td>Lord of the Rings: The Return of the King, The</td>\n      <td>Lord of the Rings: The Two Towers, The</td>\n      <td>Crouching Tiger, Hidden Dragon (Wu hu zang long)</td>\n      <td>Raiders of the Lost Ark (Indiana Jones and the...</td>\n      <td>Freaks</td>\n      <td>All About Eve</td>\n      <td>Harry Potter and the Goblet of Fire</td>\n      <td>Heathers</td>\n      <td>Sunset Blvd. (a.k.a. Sunset Boulevard)</td>\n      <td>Eternal Sunshine of the Spotless Mind</td>\n    </tr>\n    <tr>\n      <th>- fantasy</th>\n      <td>Swimmer, The</td>\n      <td>Sunrise: A Song of Two Humans</td>\n      <td>Freaks</td>\n      <td>Brokeback Mountain</td>\n      <td>Shoot the Moon</td>\n      <td>Lord of the Rings: The Return of the King, The</td>\n      <td>Night of the Hunter, The</td>\n      <td>Lord of the Rings: The Two Towers, The</td>\n      <td>Ball of Fire</td>\n      <td>Chaos</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                          1   \\\nuser history                    Talk to Her (Hable con Ella)   \ninitial recs                                    Swimmer, The   \n+ fantasy     Lord of the Rings: The Return of the King, The   \n- fantasy                                       Swimmer, The   \n\n                                                  2   \\\nuser history          Amores Perros (Love's a Bitch)   \ninitial recs                                  Freaks   \n+ fantasy     Lord of the Rings: The Two Towers, The   \n- fantasy              Sunrise: A Song of Two Humans   \n\n                                                            3   \\\nuser history             Rosencrantz and Guildenstern Are Dead   \ninitial recs                     Sunrise: A Song of Two Humans   \n+ fantasy     Crouching Tiger, Hidden Dragon (Wu hu zang long)   \n- fantasy                                               Freaks   \n\n                                                             4   \\\nuser history                                           Identity   \ninitial recs                                 Brokeback Mountain   \n+ fantasy     Raiders of the Lost Ark (Indiana Jones and the...   \n- fantasy                                    Brokeback Mountain   \n\n                                                          5   \\\nuser history                                    Mariachi, El   \ninitial recs  Lord of the Rings: The Return of the King, The   \n+ fantasy                                             Freaks   \n- fantasy                                     Shoot the Moon   \n\n                                                          6   \\\nuser history                           It Happened One Night   \ninitial recs                                  Shoot the Moon   \n+ fantasy                                      All About Eve   \n- fantasy     Lord of the Rings: The Return of the King, The   \n\n                                               7   \\\nuser history               Flirting With Disaster   \ninitial recs             Night of the Hunter, The   \n+ fantasy     Harry Potter and the Goblet of Fire   \n- fantasy                Night of the Hunter, The   \n\n                                                  8   \\\nuser history             Once Upon a Time in America   \ninitial recs  Lord of the Rings: The Two Towers, The   \n+ fantasy                                   Heathers   \n- fantasy     Lord of the Rings: The Two Towers, The   \n\n                                                  9   \\\nuser history                        Drugstore Cowboy   \ninitial recs                            Ball of Fire   \n+ fantasy     Sunset Blvd. (a.k.a. Sunset Boulevard)   \n- fantasy                               Ball of Fire   \n\n                                                  10  \nuser history                     Father of the Bride  \ninitial recs  Sunset Blvd. (a.k.a. Sunset Boulevard)  \n+ fantasy      Eternal Sunshine of the Spotless Mind  \n- fantasy                                      Chaos  "
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(outputs).set_index(0)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Pulp Fiction', 'Battleship Potemkin, The (Bronenosets Potyomkin)', 'Woman Under the Influence, A', 'Apocalypse Now', 'Seven Samurai (Shichinin no samurai)', 'Wings of Desire (Der Himmel über Berlin)', 'Son, The (Le Fils)', 'Stroszek', 'Rio Bravo', 'Wallace & Gromit: The Curse of the Were-Rabbit']\n['Pier, The (La Jetée)', '2001: A Space Odyssey', '8 1/2', 'Sunrise: A Song of Two Humans', 'Andrei Rublev (Andrey Rublyov)', 'Gerry', 'Paranoid Park', 'Wild Bunch, The', 'Red River', 'Cyclo (Xich lo)']\n2.684969023457633 -2.7016516940258937\n"
    }
   ],
   "source": [
    "user_id = 300\n",
    "sorted_items, sorted_ratings = get_user_info(user_id, dataset.train_matrix)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "\n",
    "outputs.append(['user history'] + output)\n",
    "print(output)\n",
    "\n",
    "sorted_items, sorted_ratings = get_user_preds(user_id, dataset.train_matrix)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "outputs.append(['initial recs'] + output)\n",
    "print(output)\n",
    "\n",
    "mu, cov = get_mu_cov(user_id, dataset.train_matrix, model)\n",
    "prec = np.linalg.norm(1/(cov+1e-6))\n",
    "\n",
    "prec = np.linalg.norm(1/(cov+1e-6))\n",
    "neg = np.min(mu.T @ keyphrase_embeddings.T)\n",
    "pos = np.max(mu.T @ keyphrase_embeddings.T)\n",
    "print(pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Pier, The (La Jetée)', '2001: A Space Odyssey', '8 1/2', 'Sunrise: A Song of Two Humans', 'Andrei Rublev (Andrey Rublyov)', 'Gerry', 'Paranoid Park', 'Wild Bunch, The', 'Red River', 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb']\n"
    }
   ],
   "source": [
    "x = keyphrase_embeddings[18][:,np.newaxis]\n",
    "y = [[pos]]\n",
    "\n",
    "cov1, mu1 = update_posterior(x, y, cov, mu, np.array(1))\n",
    "\n",
    "sorted_items, sorted_ratings = get_user_preds_using_mu(mu1, dataset.train_matrix, model)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "outputs.append(['+ fantasy'] + output)\n",
    "print(output)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Pier, The (La Jetée)', 'Sunrise: A Song of Two Humans', 'Sorrow and the Pity, The (Chagrin et la pitié, Le)', 'Gerry', '2001: A Space Odyssey', 'Paranoid Park', 'Andrei Rublev (Andrey Rublyov)', '8 1/2', 'Au Hasard Balthazar', 'Fat City']\n"
    }
   ],
   "source": [
    "x = keyphrase_embeddings[18][:,np.newaxis]\n",
    "y = [[neg]]\n",
    "\n",
    "cov1, mu1 = update_posterior(x, y, cov, mu, np.array(10))\n",
    "\n",
    "sorted_items, sorted_ratings = get_user_preds_using_mu(mu1, dataset.train_matrix, model)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id][:-7])\n",
    "outputs.append(['- fantasy'] + output)\n",
    "print(output)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>user history</th>\n      <td>Pulp Fiction</td>\n      <td>Battleship Potemkin, The (Bronenosets Potyomkin)</td>\n      <td>Woman Under the Influence, A</td>\n      <td>Apocalypse Now</td>\n      <td>Seven Samurai (Shichinin no samurai)</td>\n      <td>Wings of Desire (Der Himmel über Berlin)</td>\n      <td>Son, The (Le Fils)</td>\n      <td>Stroszek</td>\n      <td>Rio Bravo</td>\n      <td>Wallace &amp; Gromit: The Curse of the Were-Rabbit</td>\n    </tr>\n    <tr>\n      <th>initial recs</th>\n      <td>Pier, The (La Jetée)</td>\n      <td>2001: A Space Odyssey</td>\n      <td>8 1/2</td>\n      <td>Sunrise: A Song of Two Humans</td>\n      <td>Andrei Rublev (Andrey Rublyov)</td>\n      <td>Gerry</td>\n      <td>Paranoid Park</td>\n      <td>Wild Bunch, The</td>\n      <td>Red River</td>\n      <td>Cyclo (Xich lo)</td>\n    </tr>\n    <tr>\n      <th>+ fantasy</th>\n      <td>2001: A Space Odyssey</td>\n      <td>Pier, The (La Jetée)</td>\n      <td>8 1/2</td>\n      <td>Dr. Strangelove or: How I Learned to Stop Worr...</td>\n      <td>Wild Bunch, The</td>\n      <td>Touch of Evil</td>\n      <td>Chinatown</td>\n      <td>City Lights</td>\n      <td>Beauty and the Beast (Belle et la bête, La)</td>\n      <td>Andrei Rublev (Andrey Rublyov)</td>\n    </tr>\n    <tr>\n      <th>- fantasy</th>\n      <td>Pier, The (La Jetée)</td>\n      <td>Sunrise: A Song of Two Humans</td>\n      <td>2001: A Space Odyssey</td>\n      <td>8 1/2</td>\n      <td>Gerry</td>\n      <td>Andrei Rublev (Andrey Rublyov)</td>\n      <td>Paranoid Park</td>\n      <td>Sorrow and the Pity, The (Chagrin et la pitié,...</td>\n      <td>Fat City</td>\n      <td>Au Hasard Balthazar</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                 1   \\\nuser history           Pulp Fiction   \ninitial recs   Pier, The (La Jetée)   \n+ fantasy     2001: A Space Odyssey   \n- fantasy      Pier, The (La Jetée)   \n\n                                                            2   \\\nuser history  Battleship Potemkin, The (Bronenosets Potyomkin)   \ninitial recs                             2001: A Space Odyssey   \n+ fantasy                                 Pier, The (La Jetée)   \n- fantasy                        Sunrise: A Song of Two Humans   \n\n                                        3   \\\nuser history  Woman Under the Influence, A   \ninitial recs                         8 1/2   \n+ fantasy                            8 1/2   \n- fantasy            2001: A Space Odyssey   \n\n                                                             4   \\\nuser history                                     Apocalypse Now   \ninitial recs                      Sunrise: A Song of Two Humans   \n+ fantasy     Dr. Strangelove or: How I Learned to Stop Worr...   \n- fantasy                                                 8 1/2   \n\n                                                5   \\\nuser history  Seven Samurai (Shichinin no samurai)   \ninitial recs        Andrei Rublev (Andrey Rublyov)   \n+ fantasy                          Wild Bunch, The   \n- fantasy                                    Gerry   \n\n                                                    6                   7   \\\nuser history  Wings of Desire (Der Himmel über Berlin)  Son, The (Le Fils)   \ninitial recs                                     Gerry       Paranoid Park   \n+ fantasy                                Touch of Evil           Chinatown   \n- fantasy               Andrei Rublev (Andrey Rublyov)       Paranoid Park   \n\n                                                             8   \\\nuser history                                           Stroszek   \ninitial recs                                    Wild Bunch, The   \n+ fantasy                                           City Lights   \n- fantasy     Sorrow and the Pity, The (Chagrin et la pitié,...   \n\n                                                       9   \\\nuser history                                    Rio Bravo   \ninitial recs                                    Red River   \n+ fantasy     Beauty and the Beast (Belle et la bête, La)   \n- fantasy                                        Fat City   \n\n                                                          10  \nuser history  Wallace & Gromit: The Curse of the Were-Rabbit  \ninitial recs                                 Cyclo (Xich lo)  \n+ fantasy                     Andrei Rublev (Andrey Rublyov)  \n- fantasy                                Au Hasard Balthazar  "
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(outputs).set_index(0)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.59178778]])"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.T@keyphrase_embeddings[18][:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 'City Lights (1931)', 'Chinatown (1974)', '2001: A Space Odyssey (1968)', 'Godfather, The (1972)', 'Maltese Falcon, The (1941)', 'Annie Hall (1977)', 'Godfather: Part II, The (1974)', 'Double Indemnity (1944)', 'Treasure of the Sierra Madre, The (1948)']\n"
    }
   ],
   "source": [
    "x = keyphrase_embeddings[37][:,np.newaxis]\n",
    "y = [[2]]\n",
    "\n",
    "cov2, mu2 = update_posterior(x, y, cov1, mu1, np.array(np.linalg.norm(1/(cov1+1e-6))))\n",
    "sorted_items, sorted_ratings = get_user_preds_using_mu(mu2, dataset.train_matrix, model)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id])\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Pulp Fiction (1994)', 'Star Trek II: The Wrath of Khan (1982)', '8 1/2 (1963)', 'Sling Blade (1996)', 'Dogma (1999)', 'Fight Club (1999)', 'Third Man, The (1949)', 'Lord of the Rings: The Fellowship of the Ring, The (2001)', 'Boat, The (Das Boot) (1981)', 'Fanny and Alexander (Fanny och Alexander) (1982)']\n['Godfather, The (1972)', 'Memento (2000)', 'Usual Suspects, The (1995)', 'Face in the Crowd, A (1957)', 'Saving Private Ryan (1998)', 'Mongol (2007)', 'Bad Santa (2003)', 'Terminator 2: Judgment Day (1991)', 'Curious Case of Benjamin Button, The (2008)', 'Aliens (1986)']\n"
    }
   ],
   "source": [
    "user_id = 77\n",
    "sorted_items, sorted_ratings = get_user_info(user_id, dataset.train_matrix)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id])\n",
    "print(output)\n",
    "\n",
    "sorted_items, sorted_ratings = get_user_preds(user_id, dataset.train_matrix)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id])\n",
    "print(output)\n",
    "\n",
    "mu, cov = get_mu_cov(user_id, dataset.train_matrix, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Usual Suspects, The (1995)', 'Memento (2000)', 'Terminator 2: Judgment Day (1991)', 'Aliens (1986)', 'Saving Private Ryan (1998)', 'Godfather, The (1972)', 'X2: X-Men United (2003)', 'Gattaca (1997)', 'Spider-Man 2 (2004)', 'Monty Python and the Holy Grail (1975)']\n"
    }
   ],
   "source": [
    "x = keyphrase_embeddings[19][:,np.newaxis]\n",
    "y = [[5.]]\n",
    "\n",
    "cov1, mu1 = update_posterior(x, y, cov, mu, np.array(100))\n",
    "cov1\n",
    "sorted_items, sorted_ratings = get_user_preds_using_mu(mu1, dataset.train_matrix, model)\n",
    "top10_items = sorted_items[:10]\n",
    "output = []\n",
    "for item_id in top10_items:\n",
    "    output.append(id_title_dict[item_id])\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'anime',\n 1: 'super-hero',\n 2: 'woody allen',\n 3: 'comic book',\n 4: 'samuel l jackson',\n 5: 'brad pitt',\n 6: 'bruce willis',\n 7: 'time travel',\n 8: 'crime',\n 9: 'serial killer',\n 10: 'action',\n 11: 'jim carrey',\n 12: 'stupid',\n 13: 'dystopia',\n 14: 'drama',\n 15: 'aliens',\n 16: 'based on a book',\n 17: 'classic',\n 18: 'fantasy',\n 19: 'sci-fi',\n 20: 'space',\n 21: 'arnold schwarzenegger',\n 22: 'matt damon',\n 23: 'oscar (best actor)',\n 24: 'oscar (best picture)',\n 25: 'ghosts',\n 26: 'twist ending',\n 27: 'stephen king',\n 28: 'tom hanks',\n 29: 'interesting',\n 30: 'dvd',\n 31: 'nicolas cage',\n 32: 'magic',\n 33: 'morgan freeman',\n 34: 'bond',\n 35: 'music',\n 36: 'gay',\n 37: 'comedy',\n 38: 'funny',\n 39: 'alfred hitchcock',\n 40: 'true story',\n 41: 'family',\n 42: 'film noir',\n 43: 'heist',\n 44: 'quirky',\n 45: 'sequel',\n 46: 'memory',\n 47: 'psychology',\n 48: 'espionage',\n 49: 'satire',\n 50: 'shakespeare',\n 51: 'black comedy',\n 52: 'adventure',\n 53: 'girlie movie',\n 54: 'teen',\n 55: 'disney',\n 56: 'british',\n 57: 'sports',\n 58: 'hitchcock',\n 59: 'japan',\n 60: 'depressing',\n 61: 'great movie',\n 62: 'overrated',\n 63: 'robin williams',\n 64: 'racism',\n 65: 'boring',\n 66: 'dark comedy',\n 67: 'chick flick',\n 68: 'religion',\n 69: 'holocaust',\n 70: 'world war ii',\n 71: 'mental illness',\n 72: 'martin scorsese',\n 73: 'tom cruise',\n 74: 'steven spielberg',\n 75: 'superhero',\n 76: 'nudity (topless)',\n 77: 'drugs',\n 78: 'mystery',\n 79: 'nonlinear',\n 80: 'revenge',\n 81: 'documentary',\n 82: 'nudity (topless - brief)',\n 83: 'clint eastwood',\n 84: 'england',\n 85: 'zombies',\n 86: 'jude law',\n 87: 'hilarious',\n 88: '007',\n 89: 'james bond',\n 90: 'post-apocalyptic',\n 91: 'based on a true story',\n 92: 'vampire',\n 93: 'politics',\n 94: 'marvel',\n 95: 'animation',\n 96: 'parody',\n 97: 'police',\n 98: 'suicide',\n 99: 'historical',\n 100: 'scary',\n 101: 'fun',\n 102: 'love',\n 103: 'vampires',\n 104: 'murder',\n 105: 'thriller',\n 106: 'horror',\n 107: 'johnny depp',\n 108: 'surreal',\n 109: 'musical',\n 110: 'mel gibson',\n 111: 'remake',\n 112: 'sean connery',\n 113: 'romance',\n 114: 'violence',\n 115: 'london',\n 116: 'war',\n 117: 'martial arts',\n 118: 'lesbian',\n 119: 'death',\n 120: 'black and white',\n 121: 'cute',\n 122: 'seen more than once',\n 123: 'dark',\n 124: 'beautiful',\n 125: 'sad',\n 126: 'history',\n 127: 'disturbing',\n 128: 'children',\n 129: 'france',\n 130: 'terrorism',\n 131: 'fairy tale',\n 132: 'spoof',\n 133: 'paris',\n 134: 'cult film',\n 135: 'prison',\n 136: 'mafia',\n 137: 'organized crime',\n 138: 'predictable',\n 139: 'new york city',\n 140: 'great soundtrack',\n 141: 'underrated',\n 142: 'suspense',\n 143: 'baseball',\n 144: 'conspiracy',\n 145: 'cannibalism',\n 146: 'robots',\n 147: 'high school',\n 148: 'christmas',\n 149: 'nazis',\n 150: 'harrison ford',\n 151: 'coming of age',\n 152: 'epic',\n 153: 'new york',\n 154: 'post apocalyptic',\n 155: 'intense',\n 156: 'violent',\n 157: 'slow',\n 158: 'africa',\n 159: 'future',\n 160: 'biography',\n 161: 'boxing',\n 162: 'los angeles',\n 163: 'cars'}"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6065, 0.6066, 0.6065, 0.6909, 0.6065, 1.0357, 0.6321, 0.7306, 0.8367,\n         0.9005, 0.6890, 0.6065, 0.6202, 0.6615, 0.6069, 0.6066, 0.7204, 0.6065,\n         0.8023, 0.6065, 0.6065, 0.6065, 0.7750, 0.6070, 0.6065, 0.6065, 0.6066,\n         0.6558, 1.0224, 0.6065, 0.6390, 0.7475, 0.6065, 0.6097, 0.6065, 0.6976,\n         0.6065, 0.7138, 0.9611, 0.6307, 0.6065, 0.6065, 0.6065, 0.6065, 0.7756,\n         0.6185, 0.6075, 0.6081, 0.6065, 0.6065]])"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.logvar2std(logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1782, 4270, 3084, ..., 1858, 2873, 7813], dtype=int32)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ratings = ratings.argsort()[::-1]\n",
    "sorted_items = items[sorted_ratings]\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1115, 2345, 1815, ..., 1158, 1709, 3787])"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([5., 5., 5., ..., 1., 1., 1.])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[arr1inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =np.random.normal(np.zeros(150),0.01)\n",
    "a = a[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.013279970142235526"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(a.T@(keyphrase_embeddings.T),q=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.00175503, -0.0018365 , -0.00092557, -0.0013183 ,  0.00070177,\n       -0.00045205, -0.00063023,  0.00231926,  0.00274795, -0.00030118,\n       -0.00102944,  0.00221119, -0.00020627,  0.00062257,  0.00136277,\n        0.00194146, -0.00048117, -0.00046926,  0.00112981, -0.00067896,\n        0.00059334,  0.00093145, -0.00020276, -0.00019905, -0.00110767,\n        0.00229955,  0.00026535, -0.00072867, -0.00150996, -0.00102973,\n        0.00242328,  0.00081131,  0.00183528, -0.00051625, -0.00056769,\n       -0.00143513,  0.00020218, -0.00069088, -0.00053919,  0.00166264,\n        0.00039374,  0.00120685, -0.0008378 ,  0.00058671, -0.00062085,\n       -0.00133637,  0.00044003,  0.0004339 , -0.00023481, -0.00046481])"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(np.zeros(50),0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "12.24744871391589"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((150,150), int)\n",
    "np.fill_diagonal(a, 1)\n",
    "\n",
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictive_dist(x_pred, S, m, prec_y):\n",
    "    print(m.T)\n",
    "    pred_means = m.T @ x_pred\n",
    "    pred_means = pred_means.flatten()\n",
    "    pred_vars = np.sum(1/prec_y + x_pred.T @ S * x_pred.T, axis=1)\n",
    "\n",
    "    return pred_vars, pred_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1 2 3]]\n"
    },
    {
     "data": {
      "text/plain": "(array([39., 84.]), array([14, 20]))"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = np.array([[1,2,3],[2,3,4]]).T\n",
    "S = np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
    "m = np.array([[1],[2],[3]])\n",
    "get_predictive_dist(x_pred, S, m, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ True, False, False])"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8.999982000027002"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.linalg.norm(1/(S+1e-6)))**2"
   ]
  }
 ]
}